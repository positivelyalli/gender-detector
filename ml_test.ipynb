{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sowmyasrinivasan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sowmyasrinivasan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sowmyasrinivasan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slim = pd.read_csv('slim.csv')\n",
    "character = pd.read_csv('data/fixed_characters.csv')\n",
    "stemmed = pd.read_csv('data/final.csv')\n",
    "stemmed = stemmed.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "names = character.name.str.lower().to_list()\n",
    "sw.extend(names)\n",
    "# slimmer = slim[slim['gender'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = text.ENGLISH_STOP_WORDS.union(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# female = slimmer[slimmer['gender'] == 1]\n",
    "# male = slimmer[slimmer['gender'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_test = male.sample(n=len(female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = female.append(m_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing on one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    if \"'\" in x:\n",
    "        y = x.split(\"'\")[0]\n",
    "    else:\n",
    "        y = x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"she's they're on knowledge's door\"\n",
    "tknzr = TweetTokenizer()\n",
    "text_tokens = tknzr.tokenize(t)\n",
    "text_tokens = [split(x) for x in text_tokens]\n",
    "tokens_without_sw = [word for word in text_tokens if not word in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "words = [porter_stemmer.stem(word) for word in tokens_without_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = [lemma.lemmatize(word) for word in tokens_without_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knowledge', 'door']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialogue = []\n",
    "# for x in slimmer.dialogue:\n",
    "#     tknzr = TweetTokenizer()\n",
    "#     text_tokens = tknzr.tokenize(x)\n",
    "#     description = [lemma.lemmatize(word) for word in text_tokens]\n",
    "#     description = \" \".join(description)\n",
    "#     dialogue.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue = stemmed.dialogue.to_list()\n",
    "vec = CountVectorizer(max_features = 1000)\n",
    "vecf = vec.fit(dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vecf.transform(dialogue).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"{} most common words: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = stemmed.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5559136515658255\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"accuracy: \",nb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([ 6081, 10364]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm_rf = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "sns.heatmap(cm_rf,annot=True,cmap=\"RdPu\",fmt=\".0f\",cbar=False)\n",
    "plt.show()\n",
    "plt.savefig('confusion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fucking cry']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"i'm fucking to cry\"\n",
    "tknzr = TweetTokenizer()\n",
    "text_tokens = tknzr.tokenize(t)\n",
    "text_tokens = [split(x) for x in text_tokens]\n",
    "tokens_without_sw = [word for word in text_tokens if not word in sw]\n",
    "description = [lemma.lemmatize(word) for word in tokens_without_sw]\n",
    "words = \" \".join(description)\n",
    "words = [words]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = vecf.transform(words).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = nb.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    stemmed = pd.read_csv('stemmed.csv')\n",
    "    stemmed = stemmed.fillna('')\n",
    "    \n",
    "    dialogue = slimmer.dialogue.to_list()\n",
    "    vec = CountVectorizer(max_features = 1000)\n",
    "    vecf = vec.fit(dialogue)\n",
    "    \n",
    "    vector = vecf.transform(dialogue).toarray()\n",
    "    x = vector\n",
    "    y = slimmer.iloc[:,1].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)\n",
    "    \n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train,y_train)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(t):\n",
    "    nb = init()\n",
    "    \n",
    "    tknzr = TweetTokenizer()\n",
    "    text_tokens = tknzr.tokenize(t)\n",
    "    text_tokens = [split(x) for x in text_tokens]\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in sw]\n",
    "    description = [lemma.lemmatize(word) for word in tokens_without_sw]\n",
    "    words = \" \".join(description)\n",
    "    words = [words]\n",
    "    \n",
    "    test_x = vecf.transform(words).toarray()\n",
    "    test_y = nb.predict(test_x)\n",
    "    if test_y[0] == 0:\n",
    "        gender = 'Male'\n",
    "    else:\n",
    "        gender = 'Female'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Male'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_gender('why would you say that to me you asshole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
